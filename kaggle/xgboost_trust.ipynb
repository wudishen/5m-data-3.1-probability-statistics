{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a47831ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pythag_classic and pythag_modern\n",
      "     R   RA  pythag_classic  pythag_modern\n",
      "0  718  732       79.436008      79.568918\n",
      "1  835  751       89.556075      88.833562\n",
      "2  768  707       87.688222      87.121991\n",
      "3  713  598       95.102016      93.924738\n",
      "4  928  921       81.613296      81.561167\n",
      "Binning important continuous columns...\n",
      "  Added ERA_bin\n",
      "  Added mlb_rpg_bin\n",
      "Safe candidates for combinations: ['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA', 'E', 'DP', 'FP', 'mlb_rpg', 'franchID', 'franchID', 'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8', 'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950', 'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010', 'ERA_bin', 'mlb_rpg_bin']\n",
      "→ 48 columns\n",
      "Baseline features now include: ['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA', 'E', 'DP', 'FP', 'mlb_rpg', 'pythag_modern', 'pythag_classic']\n",
      "Baseline MAE (raw columns): 3.0271\n",
      "Added single TE: TE_franchID\n",
      "Added CE: CE_franchID\n",
      "Added single TE: TE_era_1\n",
      "Added CE: CE_era_1\n",
      "Added single TE: TE_era_2\n",
      "Added CE: CE_era_2\n",
      "Added single TE: TE_era_3\n",
      "Added CE: CE_era_3\n",
      "Added single TE: TE_era_4\n",
      "Added CE: CE_era_4\n",
      "Added single TE: TE_era_5\n",
      "Added CE: CE_era_5\n",
      "Added single TE: TE_era_6\n",
      "Added CE: CE_era_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18628/2923174209.py:175: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  counts = data_df.groupby(col).size() / len(data_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added single TE: TE_era_7\n",
      "Added CE: CE_era_7\n",
      "Added single TE: TE_era_8\n",
      "Added CE: CE_era_8\n",
      "Added single TE: TE_decade_1910\n",
      "Added CE: CE_decade_1910\n",
      "Added single TE: TE_decade_1920\n",
      "Added CE: CE_decade_1920\n",
      "Added single TE: TE_decade_1930\n",
      "Added CE: CE_decade_1930\n",
      "Added single TE: TE_decade_1940\n",
      "Added CE: CE_decade_1940\n",
      "Added single TE: TE_decade_1950\n",
      "Added CE: CE_decade_1950\n",
      "Added single TE: TE_decade_1960\n",
      "Added CE: CE_decade_1960\n",
      "Added single TE: TE_decade_1970\n",
      "Added CE: CE_decade_1970\n",
      "Added single TE: TE_decade_1980\n",
      "Added CE: CE_decade_1980\n",
      "Added single TE: TE_decade_1990\n",
      "Added CE: CE_decade_1990\n",
      "Added single TE: TE_decade_2000\n",
      "Added CE: CE_decade_2000\n",
      "Added single TE: TE_decade_2010\n",
      "Added CE: CE_decade_2010\n",
      "\n",
      "Testing 1128 safe 2-way combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 875/1128 [2:43:13<11:40,  2.77s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR ('franchID', 'franchID'): ValueError → cannot insert franchID, already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1128/1128 [2:52:39<00:00,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top improvements:\n",
      "TE_3B_decade_1950                        Δ=+0.02718  MAE=2.9999\n",
      "TE_BB_era_8                              Δ=+0.02543  MAE=3.0017\n",
      "TE_BB_decade_2010                        Δ=+0.02543  MAE=3.0017\n",
      "TE_decade_1960_ERA_bin                   Δ=+0.02435  MAE=3.0028\n",
      "TE_SO_E                                  Δ=+0.02366  MAE=3.0035\n",
      "TE_E_decade_1980                         Δ=+0.02318  MAE=3.0039\n",
      "TE_SHO_HRA                               Δ=+0.02296  MAE=3.0042\n",
      "TE_IPouts_HRA                            Δ=+0.02290  MAE=3.0042\n",
      "TE_BBA_FP                                Δ=+0.02220  MAE=3.0049\n",
      "TE_franchID_era_4                        Δ=+0.01719  MAE=3.0099\n",
      "TE_franchID_era_4                        Δ=+0.01719  MAE=3.0099\n",
      "TE_3B_decade_1920                        Δ=+0.01504  MAE=3.0121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "import itertools\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ================================================================\n",
    "#  LOAD & CLEAN\n",
    "# ================================================================\n",
    "BASE = \"input/\"\n",
    "data_df = pd.read_csv(os.path.join(BASE, \"data_year_team_franchise.csv\"))\n",
    "\n",
    "# Drop obvious leakage\n",
    "leakage = ['yearID', 'year_label', 'decade_label', 'win_bins']\n",
    "data_df = data_df.drop(columns=[c for c in leakage if c in data_df.columns], errors='ignore')\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "\n",
    "# ================================================================\n",
    "#  BASE COLUMNS — only raw safe columns (no RD, pythag, etc.)\n",
    "# ================================================================\n",
    "base_cols = [\n",
    "    'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA',\n",
    "    'BBA', 'SOA', 'E', 'DP', 'FP', 'mlb_rpg'\n",
    "]\n",
    "\n",
    "\n",
    "base_cols = [c for c in base_cols if c in data_df.columns]\n",
    "\n",
    "data_df['pythag_classic'] = 162 * (data_df['R'] ** 2) / (data_df['R'] ** 2 + data_df['RA'] ** 2 + 1e-8)\n",
    "\n",
    "# Modern exponent (more accurate, ~1.83–1.91, use 1.83 here)\n",
    "data_df['pythag_modern'] = 162 * (data_df['R'] ** 1.83) / (data_df['R'] ** 1.83 + data_df['RA'] ** 1.83 + 1e-8)\n",
    "\n",
    "print(\"Added pythag_classic and pythag_modern\")\n",
    "print(data_df[['R', 'RA', 'pythag_classic', 'pythag_modern']].head(5))\n",
    "\n",
    "\n",
    "baseline_features = base_cols + ['pythag_modern']\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "#  SAFE CANDIDATES FOR GROUPBY / TARGET ENCODING\n",
    "# ================================================================\n",
    "# Only columns that are already categorical or that we bin first\n",
    "candidates = ['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA',\n",
    "    'BBA', 'SOA', 'E', 'DP', 'FP', 'mlb_rpg', 'franchID']\n",
    "\n",
    "# Add franchise ID (most important categorical)\n",
    "if 'franchID' in data_df.columns:\n",
    "    data_df['franchID'] = data_df['franchID'].astype('category')\n",
    "    candidates.append('franchID')\n",
    "\n",
    "# Add era and decade indicators (they are binary/categorical)\n",
    "era_cols = [c for c in data_df.columns if c.startswith('era_')]\n",
    "decade_cols = [c for c in data_df.columns if c.startswith('decade_')]\n",
    "candidates.extend(era_cols)\n",
    "candidates.extend(decade_cols)\n",
    "\n",
    "# Bin continuous columns that are worth grouping on\n",
    "print(\"Binning important continuous columns...\")\n",
    "for col in ['ERA', 'mlb_rpg']:\n",
    "    if col in data_df.columns:\n",
    "        try:\n",
    "            data_df[f'{col}_bin'] = pd.qcut(\n",
    "                data_df[col].rank(pct=True),  # safer than raw values\n",
    "                q=10,\n",
    "                duplicates='drop',\n",
    "                labels=False\n",
    "            ).astype('category')\n",
    "            candidates.append(f'{col}_bin')\n",
    "            print(f\"  Added {col}_bin\")\n",
    "        except Exception as e:\n",
    "            print(f\"Binning {col} failed: {e}\")\n",
    "\n",
    "print(\"Safe candidates for combinations:\", candidates)\n",
    "print(f\"→ {len(candidates)} columns\")\n",
    "\n",
    "# If no candidates left → fallback\n",
    "if not candidates:\n",
    "    print(\"No safe candidates! Using only franchID if present.\")\n",
    "    if 'franchID' in data_df.columns:\n",
    "        candidates = ['franchID']\n",
    "\n",
    "# ──── FAST CV EVALUATION ────────────────────────────────────────────\n",
    "def quick_cv_mae(df, features, target='W', n_estimators=400, lr=0.08, depth=4):\n",
    "    features = [f for f in features if f in df.columns]\n",
    "    if not features:\n",
    "        return np.inf  # bad case\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    maes = []\n",
    "\n",
    "    for tr_idx, va_idx in kf.split(X):\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=lr,\n",
    "            max_depth=depth,\n",
    "            subsample=0.85,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        )\n",
    "        model.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "        pred = model.predict(X.iloc[va_idx])\n",
    "        maes.append(mean_absolute_error(y.iloc[va_idx], pred))\n",
    "\n",
    "    return np.mean(maes)\n",
    "\n",
    "# ================================================================\n",
    "#  TARGET ENCODING FUNCTION (already good — small tweak)\n",
    "# ================================================================\n",
    "def safe_target_encode(df, cols, target='W', folds=5, smooth=20.0):\n",
    "    missing = [c for c in cols + [target] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns: {missing}\")\n",
    "\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    te_values = np.full(len(df), np.nan)\n",
    "    global_mean = df[target].mean()\n",
    "\n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        train_df = df.iloc[train_idx].copy()\n",
    "        val_df   = df.iloc[val_idx].copy()\n",
    "\n",
    "        grp = train_df.groupby(cols, observed=True)[target].agg(\n",
    "            ['mean', 'count']\n",
    "        ).reset_index()\n",
    "        grp['smoothed'] = (grp['mean'] * grp['count'] + global_mean * smooth) / (grp['count'] + smooth)\n",
    "\n",
    "        merged = val_df[cols].merge(\n",
    "            grp[cols + ['smoothed']],\n",
    "            on=cols,\n",
    "            how='left'\n",
    "        )\n",
    "        te_values[val_idx] = merged['smoothed'].fillna(global_mean).values\n",
    "\n",
    "    return pd.Series(te_values, index=df.index, name=f\"TE_{'_'.join(cols)}\")\n",
    "\n",
    "# ================================================================\n",
    "#  BASELINE (raw columns only)\n",
    "# ================================================================\n",
    "baseline_features = base_cols.copy()\n",
    "# Add the pythag columns you created\n",
    "\n",
    "if 'pythag_modern' in data_df.columns:\n",
    "    baseline_features.append('pythag_modern')\n",
    "if 'pythag_classic' in data_df.columns:\n",
    "    baseline_features.append('pythag_classic')\n",
    "    \n",
    "\n",
    "print(\"Baseline features now include:\", baseline_features)\n",
    "baseline_mae = quick_cv_mae(data_df, baseline_features)\n",
    "print(f\"Baseline MAE (raw columns): {baseline_mae:.4f}\")\n",
    "\n",
    "# ================================================================\n",
    "#  ADD SINGLE TE/CE ON FRANCHID + ERA/DECADE (very strong!)\n",
    "# ================================================================\n",
    "for col in ['franchID'] + era_cols + decade_cols:\n",
    "    if col in data_df.columns:\n",
    "        te = safe_target_encode(data_df, [col], smooth=20)\n",
    "        data_df[te.name] = te\n",
    "        print(f\"Added single TE: {te.name}\")\n",
    "\n",
    "        # Count encode\n",
    "        ce_name = f\"CE_{col}\"\n",
    "        counts = data_df.groupby(col).size() / len(data_df)\n",
    "        data_df[ce_name] = data_df[col].map(counts).fillna(0)\n",
    "        print(f\"Added CE: {ce_name}\")\n",
    "\n",
    "# ================================================================\n",
    "#  COMBINATION SEARCH — only on safe candidates\n",
    "# ================================================================\n",
    "if len(candidates) >= 2:\n",
    "    all_pairs = list(itertools.combinations(candidates, 2))\n",
    "    print(f\"\\nTesting {len(all_pairs)} safe 2-way combinations...\")\n",
    "\n",
    "    accepted_features = []\n",
    "    improvements = []\n",
    "\n",
    "    for comb in tqdm(all_pairs):\n",
    "        try:\n",
    "            te_series = safe_target_encode(data_df, list(comb), smooth=10.0)\n",
    "            temp_df = data_df.copy()\n",
    "            temp_df[te_series.name] = te_series\n",
    "\n",
    "            trial_features = baseline_features + [te_series.name]\n",
    "            new_mae = quick_cv_mae(temp_df, trial_features)\n",
    "            delta = baseline_mae - new_mae\n",
    "\n",
    "           # print(f\"{str(comb):35} → Δ={delta:+.4f}  new={new_mae:.4f}\")\n",
    "\n",
    "            if delta > 0.005:  # stricter threshold now\n",
    "                accepted_features.append(te_series.name)\n",
    "                improvements.append((te_series.name, delta, new_mae))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR {comb}: {type(e).__name__} → {str(e)}\")\n",
    "\n",
    "    # Show results\n",
    "    if improvements:\n",
    "        improvements.sort(key=lambda x: x[1], reverse=True)\n",
    "        print(\"\\nTop improvements:\")\n",
    "        for n, d, m in improvements[:12]:\n",
    "            print(f\"{n:40} Δ={d:+.5f}  MAE={m:.4f}\")\n",
    "    else:\n",
    "        print(\"No strong combinations found.\")\n",
    "else:\n",
    "    print(\"Not enough safe candidates to form 2-way combinations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a7b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE without pythag: 3.1331\n",
      "MAE with pythag_modern: 3.0550\n",
      "Improvement from adding pythag: +0.0781 MAE\n"
     ]
    }
   ],
   "source": [
    "data_df['pythag_modern'] = 162 * (data_df['R'] ** 1.83) / (data_df['R'] ** 1.83 + data_df['RA'] ** 1.83 + 1e-8)\n",
    "\n",
    "# Baseline without pythag\n",
    "mae_no_pythag = quick_cv_mae(data_df, base_cols)\n",
    "print(f\"MAE without pythag: {mae_no_pythag:.4f}\")\n",
    "\n",
    "# Baseline with pythag\n",
    "mae_with_pythag = quick_cv_mae(data_df, base_cols + ['pythag_modern'])\n",
    "print(f\"MAE with pythag_modern: {mae_with_pythag:.4f}\")\n",
    "\n",
    "# Improvement\n",
    "delta = mae_no_pythag - mae_with_pythag\n",
    "print(f\"Improvement from adding pythag: {delta:+.4f} MAE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
