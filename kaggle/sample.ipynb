{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb66ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set shape: (1812, 51)\n",
      "Predict set shape: (453, 45)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def add_strong_features(df):\n",
    "    # Core run-related (usually the strongest predictors)\n",
    "    df['run_diff'] = df['R'] - df['RA']\n",
    "    df['run_diff_per_game'] = df['run_diff'] / df['G']\n",
    "    \n",
    "    # Pythagorean (modern exponent)\n",
    "    exp = 1.83\n",
    "    df['pyth_exp'] = np.where(\n",
    "        df['R'] + df['RA'] > 0,\n",
    "        df['R']**exp / (df['R']**exp + df['RA']**exp),\n",
    "        0.5\n",
    "    )\n",
    "    df['pyth_wins'] = np.round(df['G'] * df['pyth_exp']).astype(int)\n",
    "    \n",
    "    # Per-game rates (helps across eras)\n",
    "    df['R_per_game']  = df['R'] / df['G']\n",
    "    df['RA_per_game'] = df['RA'] / df['G']\n",
    "    \n",
    "    # Pitching quality\n",
    "    df['IP'] = df['IPouts'] / 3.0 + 1e-6          # avoid division by zero\n",
    "    df['SOA_per_game'] = df['SOA'] / df['IP']\n",
    "    df['WHIP'] = (df['HA'] + df['BBA']) / df['IP']\n",
    "    \n",
    "    # Other useful differentials & adjustments\n",
    "    df['HR_diff'] = df['HR'] - df['HRA']\n",
    "    df['ERA_adj'] = df['ERA'] - df['mlb_rpg'] * 9     # rough league adjustment\n",
    "    \n",
    "    # Late-game / bullpen strength\n",
    "    # df['SV_rate'] = df['SV'] / (df['SV'] + df['BS'] + 1e-6)  # if you have blown saves\n",
    "    \n",
    "    # Market/team quality proxy\n",
    "    df['attendance_per_game'] = df['attendance'] / df['G']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the pre-processed train and test datasets\n",
    "#DATAPATH = \"sctpdsai-m-3-ds-3-coaching-money-ball-analytics\"\n",
    "BASE = f\"input/\"\n",
    "data_df = pd.read_csv(os.path.join(BASE, \"data.csv\"))\n",
    "predict_df = pd.read_csv(os.path.join(BASE, \"predict.csv\"))\n",
    "\n",
    "# Display basic information about the datasets\n",
    "print(f\"Data set shape: {data_df.shape}\")\n",
    "print(f\"Predict set shape: {predict_df.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47831ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available default features: 44\n",
      "['G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA', 'E', 'DP', 'FP', 'mlb_rpg', 'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8', 'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950', 'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010']\n"
     ]
    }
   ],
   "source": [
    "default_features = [\n",
    "    # Basic Statistics\n",
    "    'G', 'R', 'AB', 'H', '2B', '3B', 'HR', 'BB', 'SO', 'SB', 'CS', 'HBP', 'SF',\n",
    "    'RA', 'ER', 'ERA', 'CG', 'SHO', 'SV', 'IPouts', 'HA', 'HRA', 'BBA', 'SOA',\n",
    "    'E', 'DP', 'FP', 'attendance', 'BPF', 'PPF',\n",
    "    \n",
    "    # Derived Features\n",
    "    'R_per_game', 'RA_per_game', 'mlb_rpg',\n",
    "    \n",
    "    # Era Indicators\n",
    "    'era_1', 'era_2', 'era_3', 'era_4', 'era_5', 'era_6', 'era_7', 'era_8',\n",
    "    \n",
    "    # Decade Indicators\n",
    "    'decade_1910', 'decade_1920', 'decade_1930', 'decade_1940', 'decade_1950',\n",
    "    'decade_1960', 'decade_1970', 'decade_1980', 'decade_1990', 'decade_2000', 'decade_2010'\n",
    "]\n",
    "\n",
    "strong_features = [\n",
    "    'run_diff',\n",
    "    'run_diff_per_game',\n",
    "    'pyth_wins',\n",
    "    'pyth_exp',\n",
    "    'R_per_game',\n",
    "    'RA_per_game',\n",
    "    'ERA',\n",
    "    'WHIP',\n",
    "    'SOA_per_game',\n",
    "    'HR_diff',           # added — often stronger than separate HR/HRA\n",
    "    'HRA',\n",
    "    'SV',\n",
    "    'SHO',\n",
    "    'mlb_rpg',\n",
    "    'ERA_adj',\n",
    "    'era_8',\n",
    "    'attendance_per_game',\n",
    "    # Optional high-value extras (add if your CV likes them):\n",
    "    # 'FP', 'DP', 'E', 'BB', 'SO'\n",
    "]\n",
    "\n",
    "# Filter features that exist in both datasets\n",
    "available_features = [col for col in default_features if col in data_df.columns and col in predict_df.columns]\n",
    "print(f\"Number of available default features: {len(available_features)}\")\n",
    "print(available_features)\n",
    "\n",
    "\n",
    "data_df   = add_strong_features(data_df)\n",
    "predict_df = add_strong_features(predict_df)\n",
    "\n",
    "print(\"Strong features ready:\", strong_features)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_df[available_features]\n",
    "y = data_df['W']\n",
    "\n",
    "# Perform the split (adjust test_size / random_state as needed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42    # ensures reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fbd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale features\n",
    "# Identify columns to exclude from scaling (one-hot encoded and label columns)\n",
    "one_hot_cols = [col for col in X_train.columns if col.startswith(('era_', 'decade_'))]\n",
    "other_cols = [col for col in X_train.columns if col not in one_hot_cols]\n",
    "\n",
    "# Scale only non-one-hot features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[other_cols] = scaler.fit_transform(X_train[other_cols])\n",
    "X_test_scaled[other_cols] = scaler.transform(X_test[other_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6476c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Linear Regression Model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_train_preds = lr.predict(X_train_scaled)\n",
    "lr_test_preds = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Linear Regression\n",
    "lr_train_mae = mean_absolute_error(y_train, lr_train_preds)\n",
    "lr_test_mae = mean_absolute_error(y_test, lr_test_preds)\n",
    "lr_test_rmse = np.sqrt(mean_squared_error(y_test, lr_test_preds))\n",
    "lr_test_r2 = r2_score(y_test, lr_test_preds)\n",
    "\n",
    "print(f\"Linear Regression Performance:\")\n",
    "print(f\"  Training MAE: {lr_train_mae:.4f}\")\n",
    "print(f\"  Test MAE: {lr_test_mae:.4f}\")\n",
    "print(f\"  Test RMSE: {lr_test_rmse:.4f}\")\n",
    "print(f\"  Test R²: {lr_test_r2:.4f}\")\n",
    "\n",
    "# Feature importance from Linear Regression\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': lr.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, lr_test_preds, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Wins')\n",
    "plt.ylabel('Predicted Wins')\n",
    "plt.title('Linear Regression: Actual vs Predicted Wins')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "residuals = y_test - lr_test_preds\n",
    "plt.scatter(lr_test_preds, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Wins')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Linear Regression: Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Submission\n",
    "\n",
    "# Align features and scale using the previously fitted scaler\n",
    "predict_scaled = predict_df[available_features].copy()\n",
    "predict_scaled[other_cols] = scaler.transform(predict_scaled[other_cols])\n",
    "\n",
    "# Predict wins for the new dataset\n",
    "predict_preds = lr.predict(predict_scaled)\n",
    "\n",
    "# Build submission in the same format as submission.csv\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': predict_df['ID'],\n",
    "    'W': np.round(predict_preds).astype(int)\n",
    "})\n",
    "\n",
    "submission_path = 'submission_predict.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "print(f\"Kaggle submission saved to {submission_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
